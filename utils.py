# -*- coding: utf-8 -*-
"""utils

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s2bu1m77LuLhCOZVomb5dpru5pASx7Dv
"""

#Utility Functions

import torch
from optimization import *
from tqdm import tqdm

def matrix_operations(A, E_combined, x1_positive, sigma, known):
    """
    Perform matrix operations used in the optimization computation.

    Args:
    A (torch.Tensor): The matrix A from the optimization context.
    E_combined (torch.Tensor): The combined known and learned parts of matrix E.
    x1_positive (torch.Tensor): Vector x1 with softplus applied.
    sigma (torch.Tensor): Combined known and learned parts of matrix Sigma.

    Returns:
    tuple: Contains expanded forms of E*x and Sigma*x1 as well as simple E*x for further calculations.
    """
    E_x = torch.matmul(E_combined, x1_positive)
    if known:
        E_x_expanded = E_x.unsqueeze(1).expand(-1, A.size(0))
        E_x_expanded_full = E_x_expanded.repeat(A.size(0) // E_x_expanded.size(0), 1)
    else:
        E_x_expanded = E_x.unsqueeze(1).expand(-1, A.size(1))
        E_x_expanded_full = E_x_expanded.repeat(A.size(0) // E_x_expanded.size(0), 1)
    sigma_x1 = torch.matmul(sigma, x1_positive)
    return E_x_expanded_full, sigma_x1, E_x

def compute_determinant_approx(x):
    """
    Computes an approximation of the determinant by multiplying singular values of the matrix.

    Args:
    x (torch.Tensor): Matrix to compute the determinant approximation of.

    Returns:
    torch.Tensor: Product of singular values, an approximation of the determinant.
    """
    u, s, vh = torch.linalg.svd(x, full_matrices=False)
    return torch.prod(s)


def compute_positive(x):
    return torch.nn.functional.softplus(x)

def calculate_errors(i, W, num_samples,  C1, x1_size, A_list, D_list, E, Sigma, ground_truth_fracs, known, num_epochs):
    A = A_list[i]
    A = A.T.flatten()
    D = D_list[i]
    ground_truth_frac = ground_truth_fracs[i]
    A_jacob = A.reshape((10,50))

    D_jacob = D.T
    E_jacob = E.T
    Sigma_jacob = Sigma.T

    teddy_errors = []
    jacob_errors = []

    for _ in tqdm(range(num_samples), desc=f"i = {i}, W = {W}"):
        x1 = grad_descent_known(C1, C2=0, C3=0, C4=0, C5=0, P=0, L=0, W=W, x1_size=x1_size, A=A, D=D, E=E, Sigma=Sigma, known=known)
        jacob_results = pytorch_cov_prediction(A_jacob, E_jacob, D_jacob, Sigma_jacob, W, 1, 1, num_epochs=num_epochs)
        
        x1 = x1.squeeze()
        teddy_alpha = x1 / sum(x1)
        jacob_alpha = jacob_results[0]

        ted_error = L1_norm(teddy_alpha, ground_truth_frac)
        jacob_error = L1_norm(jacob_alpha, ground_truth_frac)
        
        teddy_errors.append(ted_error)
        jacob_errors.append(jacob_error)
    
    return np.mean(teddy_errors), np.std(teddy_errors), np.mean(jacob_errors), np.std(jacob_errors)
