# -*- coding: utf-8 -*-
"""utils

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s2bu1m77LuLhCOZVomb5dpru5pASx7Dv
"""

#Utility Functions

import torch


def matrix_operations(A, E_combined, x1_positive, sigma):
    """
    Perform matrix operations used in the optimization computation.

    Args:
    A (torch.Tensor): The matrix A from the optimization context.
    E_combined (torch.Tensor): The combined known and learned parts of matrix E.
    x1_positive (torch.Tensor): Vector x1 with softplus applied.
    sigma (torch.Tensor): Combined known and learned parts of matrix Sigma.

    Returns:
    tuple: Contains expanded forms of E*x and Sigma*x1 as well as simple E*x for further calculations.
    """
    E_x = torch.matmul(E_combined, x1_positive)
    E_x.shape()
    E_x_expanded = E_x.unsqueeze(1).expand(-1, A.size(0) // E_x.size(0)).reshape(-1)
    E_x_expanded_full = E_x_expanded.repeat(A.size(0) // E_x_expanded.size(0), 1)
    sigma_x1 = torch.matmul(sigma, x1_positive)
    return E_x_expanded_full, sigma_x1, E_x

def compute_determinant_approx(x):
    """
    Computes an approximation of the determinant by multiplying singular values of the matrix.

    Args:
    x (torch.Tensor): Matrix to compute the determinant approximation of.

    Returns:
    torch.Tensor: Product of singular values, an approximation of the determinant.
    """
    u, s, vh = torch.linalg.svd(x, full_matrices=False)
    return torch.prod(s)


def compute_positive(x):
    return torch.nn.functional.softplus(x)


